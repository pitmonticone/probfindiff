{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9710639",
   "metadata": {},
   "source": [
    "# Finite differences and modelling\n",
    "\n",
    "This notebooks explains a few of the subtleties of common assumptions behind finite difference schemes.\n",
    "\n",
    "It will also outline one of the key advantages of `pnfindiff` over competing packages: _making modelling explicit_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "844a0ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pnfindiff import differentiate, central\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a804e834",
   "metadata": {},
   "source": [
    "Whenever you use `pnfindiff`, remember that you are essentially building a Gaussian process model.\n",
    "The computation of the PN finite difference schemes assumes that the to-be-differentiated function $f$ is \n",
    "$$\n",
    "f \\sim GP(0, k)\n",
    "$$\n",
    "for some covariance kernel function $k$. (This assumptions is implicit in non-probabilistic schemes -- more on this later).\n",
    "This assumption is inherent in the `pnfindiff` code.\n",
    "Central, forward, backward, and custom schemes automatically tailor to Gaussian covariance kernel functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7faf30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FiniteDifferenceScheme(weights=DeviceArray([-7.014634e-01,  4.714658e-08,  7.014634e-01], dtype=float32), covs_marginal=DeviceArray(0.14908189, dtype=float32), order_derivative=DeviceArray(1, dtype=int32, weak_type=True))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_exp_quad = lambda x, y: jnp.exp(-jnp.dot(x - y, x - y) / 2.0)\n",
    "\n",
    "scheme, xs = central(dx=1.0, kernel=k_exp_quad)\n",
    "scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70dc612",
   "metadata": {},
   "source": [
    "Did you know that traditional finite difference coefficients $c=(1, -2, 1)$ implicitly assume that the function to-be-differentiated is a polynomial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d2fe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -2.  1.] True\n"
     ]
    }
   ],
   "source": [
    "k_poly = lambda x, y: jnp.polyval(x=jnp.dot(x, y), p=jnp.ones((3,)))\n",
    "scheme, xs = central(dx=1.0, order_derivative=2, kernel=k_poly)\n",
    "print(scheme.weights, jnp.allclose(scheme.weights, jnp.array([1.0, -2.0, 1.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a8347",
   "metadata": {},
   "source": [
    "Whether this is right or wrong for your application, has to be decided by yourself.\n",
    "So next time you choose a finite difference scheme, please remember that you do not have to live like this, and that you can indeed compute finite difference formulas that are perfect for your model (and not build a model that uses some magic finite difference scheme)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27e7500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fde6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
